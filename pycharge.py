import numpy as np
import xarray as xr
import os
import pandas as pd
from scipy.optimize import brentq
from scipy import linalg as scLA
import charge_fields
import utils
lats = ['square', 'triangle', 'rtriangle']

def process_lattice(lat, use_cache=True, porosity=None, layers_to_keep=None):
    """
    The first step  of the calcualtion is obtaining the interaction matrices between the charges, 
    and the matrices that describe the boundary conditions. As described in the paper (Eq. (??)), 
    these can be obtained by direct numerical integration.

    The numerical integration is done in the following way:
    1. A Finite Element (FE) mesh of the domain is generated in MATLAB. 
    2. The mesh is analyzed and saved as a .mat file in data/charges/LATTICE_meshes.mat
    3. Each file contains variables named geom_XXX where XXX stands for 1000 the porosity, i.e.
       geom_450 is the geometry variable for porosity 0.45.
    4. The interaction matrices are computed in calc_matrices, see docs within for how it's done.

    args:
        lat: The lattice name, should be one of  ['square','triangle','rtriangle'].
        use_cache: To To save time, when this function is run it saves its output. To force
            recalculating, use use_cache=False.
        porosity: The porosity to compute stuff for. If porosity is None, we go over all porosities
            and return the concatenated result.
        layers_to_keep: How many layers of charges outside the bulk to keep (see Fig. ? in the paper).
            If None, keep all layers.

    returns:
        A xr.Dataset containing the interaction matrices and all other data needed to calculate linear
        response, instability, etc.

    """
    fname = f'data/{lat}_matrices.nc'
    if use_cache and os.path.isfile(fname):
        print(f'reading from {fname}')
        ds = xr.open_dataset(fname)
        ds.coords['lattice'] = lat
        if layers_to_keep is not None:
            ds = remove_layers(ds, layers_to_keep=layers_to_keep)
        if porosity is not None:
            ds = ds.sel(porosity=porosity)

        return ds

    dat = utils.loadmat(f'data/charges/{lat}_meshes.mat')
    holes, hole_layers = get_holes(dat)
    if layers_to_keep is not None:
        idx = (hole_layers <= layers_to_keep)
        hole_layers = hole_layers[idx]
        holes = holes[idx]
    holes_d, hole_layers_d = duplicate_holes_for_charges(holes, hole_layers)

    if porosity is None:
        # If porosity is not given, go over all porosities and concatenate.
        ds = xr.concat(
            [calc_matrices(g, holes) for k, g in dat.items() if k.startswith('geom_')], 
            'porosity')
    else:
        g = dat[f'geom_{int(1000*porosity)}']
        ds = calc_matrices(g, holes)
        ds.coords['porosity'] = porosity

    ds['layers_by_charge'] = (['charge'], hole_layers_d)
    ds['holes_by_charge'] = (['charge', 'xy'], holes_d)
    ds['layers_by_hole'] = (['hole'], hole_layers)
    ds['holes'] = (['hole', 'xy'], holes)
    ds.coords['lattice'] = lat
    ds.coords['xy'] = [0, 1]
    if porosity is None:
        print(f'saving to {fname}')
        ds.to_netcdf(fname)
    return ds


def linear_response(data, return_as='copy', layers_to_keep=None):
    """"Takes a dataset generated by process_lattice and calculates its linear response."""
    if return_as == 'copy':
        result = data.copy()
    elif return_as == 'merge':
        result = data
    elif return_as == 'separate':
        result = xr.Dataset({}, coords={'lattice': data.lattice.values,
                                        'porosity': data.lattice.porosity})
    else:
        raise ValueError(f'return as "{return_as}" not understood')

    if layers_to_keep is not None:
        data = remove_layers(data, layers_to_keep, trim_corners=True)

    N = generate_constraints(data)
    M = data.M1.values
    N1 = np.atleast_2d(N.sel(order=1).values)
    D = xr.ones_like(N.constraint)
    iMN = utils.lstsq(M, N1)
    Q0 = -iMN @ utils.lstsq(N1.T @ iMN, D)

    E = Q0.T @ M @ Q0
    Y = 0.5 * (data.height/data.width) * E

    result['N1'] = N[0]
    result['N2'] = N[1]
    result['Q0'] = ('charge', Q0)
    result['Y'] = ([], Y)
    result['charge'] = data.charge
    return result


def generate_constraints(data):
    return (data
            .edge_displacements
            .mean('edge_node')
            .rename(edge='constraint')
            .transpose('order', 'charge', 'constraint'))


def nl_response(data, return_as='copy', n_modes=7):
    if return_as == 'copy':
        result = data.copy()
    elif return_as == 'merge':
        result = data
    else:
        raise ValueError(f'return as "{return_as}" not understood')

    if 'Q0' in data.data_vars:
        Q0 = data.Q0.values
    else:
        LR = linear_response(data)
        Q0 = LR.Q0.values

    M2 = data.M2.values
    M2Q0 = M2.T * Q0    # M.T*Q is the same as M.T @ np.diag(Q)
    dH = 2 * (M2Q0 + M2Q0.T + np.diag(M2 @ Q0))
    dN = 2 * np.diag(Q0) @ data.N2.values
    result['dN'] = (data.N1.dims, dN)
    result['dH'] = (data.M1.dims, dH)

    delta_c = brentq(lambda dd: unstable_modes_and_eigenvalues(result, dd, n_modes=1)[1],
                     0, 0.7)

    deltas = np.linspace(0, 0.45)
    eigenvalues = np.zeros((len(deltas), n_modes))
    eigenmodes = np.zeros((len(deltas), len(Q0), n_modes))
    for i, d in enumerate(deltas):
        modes, values = unstable_modes_and_eigenvalues(result, d, n_modes=n_modes)
        eigenmodes[i] = modes
        eigenvalues[i] = values

    cmode, _ = unstable_modes_and_eigenvalues(result, delta_c, n_modes)
    #assert np.abs(should_be_zero) < 1e-8

    result['delta_c'] = ([], delta_c)
    result['eigenvalues'] = (['delta', 'mode'], eigenvalues)
    result['eigenmodes'] = (['delta', 'charge', 'mode'], eigenmodes)
    result['cmodes'] = (['charge', 'mode'], cmode)
    result['Q0'] = (['charge'], Q0)
    result['delta'] = deltas
    return result


def unstable_modes_and_eigenvalues(data, d, n_modes=7):
    Hp, P = projected_hessian(data, d, return_P=True)
    ev, q = scLA.eigh(Hp, eigvals=(0, n_modes - 1))
    return P@q, ev      # (eigenvectors, eigenvalues)


def projected_hessian(data, d, return_P=False):
    P = scLA.null_space((data.N1 + d * data.dN).T)
    Mp = P.T @ (data.M1.values + d * data.dH.values) @ P
    if return_P:
        return Mp, P
    else:
        return Mp


def calc_matrices(g, holes):
    print(f'p={g.porosity}:')
    print('  charges...', end='')
    charges = calc_charge_fields(g, holes=holes)
    print('done\n  edge displacements...', end='')
    edge_displacements = calc_edge_displacements(g, charges)
    print('done\n  M1...', end='')
    M1 = bulk_inner_product(charges.s, charges.s, g.bulkVector)
    print('done\n  M2...', end='')
    M2 = bulk_inner_product(charges.s, charges.s2, g.bulkVector)

    print('done')
    ds = xr.Dataset({'M1': (['charge', 'charge2'], M1),
                     'M2': (['charge', 'charge2'], M2),
                     'height': ([], g.H),
                     'width': ([], g.W),
                     'loading_length': ([], g.topVector.sum() + g.bottomVector.sum()),
                     },
                    coords={'charge': range(M1.shape[0]),
                            'charge2': range(M1.shape[0]),
                            'porosity': g.porosity})
    ds = xr.merge([ds, edge_displacements])
    return ds


def calc_edge_displacements(g, charges):
    """
    Returns a pd.Series of loading edges, each element is an array with the
    indices of the nodes in that edge.
    """
    edges, _ = all_edges(g)
    M = max(edges.y1.max(), edges.y2.max())
    m = min(edges.y1.min(), edges.y2.min())

    def collect_boundary_edges(y):
        nodelist = (edges
                    .loc[(edges.y1 == y) & (edges.y2 == y)]
                    .groupby('edge_label')
                    .apply(lambda es: np.unique(np.concatenate([es.i1, es.i2])))
                    )
        nodelist = [xr.DataArray([row],
                                 dims=['edge', 'edge_node'],
                                 coords={'edge_node': range(len(row))})
               for row in nodelist]
        nodelist = xr.concat(nodelist, 'edge')
        dlist = xr.concat([charges.d.isel(space=1, node=a).drop('node') for a in nodelist], 'edge')
        return dlist, nodelist

    top, top_nodes = collect_boundary_edges(M)
    bottom, bottom_nodes = collect_boundary_edges(m)
    edges = xr.concat([top, -bottom], 'edge')
    edge_nodes = xr.concat([top_nodes, bottom_nodes], 'edge')
    edge_sides = xr.concat([xr.full_like(top_nodes.edge, 1),
                            xr.full_like(top_nodes.edge, -1)
                            ], 'edge')
    ds = xr.Dataset({'edge_displacements': edges,
                     'edge_nodes': edge_nodes,
                     'edge_sides': edge_sides})
    return ds


def calc_charge_fields(ds, holes=None, nodes=None,
                       only_outline=False, stress=None, reference=None):
    if 'p' not in ds:
        g = get_geom(ds)
    else:
        g = ds

    if holes is None:
        holes = ds.holes.values

    if nodes is None:
        if only_outline:
            edges, nodes = all_edges(g)
            inds = np.unique(np.concatenate([edges.i1, edges.i2]))
            nodes = nodes[:, inds]
            if reference is None:
                reference = True
        else:
            if stress is None:
                stress = True
            nodes = g.p
    elif only_outline:
        raise ValueError('can''t specify nodes and outline_only=True simultaneously')

    tmp = [charge_fields.hole_charges(hole, nodes, stress=stress) for hole in holes]

    charges = xr.concat(tmp, 'charge')
    charges['node'] = inds if only_outline else range(len(charges.node))
    charges.coords['order'] = [1, 2]
    if isinstance(ds, (xr.DataArray, xr.Dataset)) and 'charge' in ds.coords:
        charges.coords['charge'] = ds.coords['charge']
    else:
        charges.coords['charge'] = range(len(charges.charge))

    if reference:
        charges['reference'] = (['space', 'node'], nodes)

    return charges


def bulk_inner_product(s1, s2, W, nu=0.3):
    """Computes the inner product of two stress fields over the bulk, as described in Eq (?) in the paper.
        
        W is ...
    """
    Adown = np.array([
        [1, 0, -nu],
        [0, 2 * (1 + nu), 0],
        [-nu, 0, 1]])
    e2 = np.einsum('ij,cjn->icn', Adown, s2)  # dimension of e2: ('space2', 'charge', 'node')
    M = 0.5 * np.tensordot(e2 * [[W]], s1, [[0, 2], [1, 2]])
    return M


def get_holes(dat):
    """Returns the hole positions and the layer of each hole from a loaded .mat file."""
    if isinstance(dat, str):
        for fname in [f'data/charges/{dat}_meshes.mat', dat]:
            if os.path.isfile(fname):
                dat = utils.loadmat(fname)
                break

    holes = np.vstack([[np.inf, np.inf], dat.holes])
    hole_layers = np.concatenate([[-1], dat.hole_layers])
    return holes, hole_layers


def duplicate_holes_for_charges(holes, hole_layers):
    """Duplicate each hole 5 times, because each charge has 5 degrees of freedom."""
    holes_d = np.vstack([[h] * 5 for h in holes])
    hole_layers_d = np.c_[[hole_layers] * 5].T.flat[:]
    return holes_d, hole_layers_d


def remove_layers(ds, layers_to_keep=1, trim_corners=False):
    """Removes outer layers of charges from the computation."""
    inds_c = (ds.layers_by_charge <= layers_to_keep).values
    inds_h = (ds.layers_by_hole <= layers_to_keep).values

    if trim_corners:
        inds_trim_h = sum([
            np.abs(ds.holes[:, 0]) > (0.1 + ds.width / 2),
            np.abs(ds.holes[:, 1]) > (0.1 + ds.height / 2),
        ]) <= 1
        inds_trim_c = sum([
            np.abs(ds.holes_by_charge[:, 0]) > (0.1 + ds.width / 2),
            np.abs(ds.holes_by_charge[:, 1]) > (0.1 + ds.height / 2),
        ]) <= 1

        inds_c = np.logical_and(inds_c, inds_trim_c).values
        inds_h = np.logical_and(inds_h, inds_trim_h).values

    inds_c[ds.layers_by_charge == -1] = True  # Don't delete the infinity charges!
    inds_h[ds.layers_by_hole == -1] = True    # Don't delete the infinity charges!
    ds = (ds
          .copy()
          .isel(charge=inds_c, charge2=inds_c)
          .isel(hole=inds_h)
          )

    return ds


def all_edges(g):
    """
    returns a DataFrame. each row is a segment of an edge.
    g is a mesh structure such as
        loadmat(f'data/charges/{lat}_meshes.mat').geom_600
    """
    if 'p' not in g:
        g = get_geom(g)

    nodes = g.p
    edges = pd.DataFrame(g.e[[0, 1, 4, 5, 6]].T.astype('i'),
                         columns=['i1', 'i2', 'edge_label', 'region1', 'region2'])
    edges['i1'] = edges['i1'] - 1  # fix MATLAB to python indexing
    edges['i2'] = edges['i2'] - 1  # fix MATLAB to python indexing
    edges['x1'] = nodes[0, edges.i1]
    edges['x2'] = nodes[0, edges.i2]
    edges['y1'] = nodes[1, edges.i1]
    edges['y2'] = nodes[1, edges.i2]

    return edges, nodes


def get_geom(lat, porosity=0.6):
    if isinstance(lat, (xr.Dataset, xr.DataArray)):
        assert lat.porosity.size == 1, "pass a ds with a single porosity to get_geom"
        porosity = lat.porosity.values
        lat = lat.lattice.values
    dat = utils.loadmat(f'data/charges/{lat}_meshes.mat')
    return dat[f'geom_{int(1000*porosity)}']


